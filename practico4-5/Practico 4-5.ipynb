{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiploDatos 2019 - Análisis de Series Temporales\n",
    "\n",
    "## Integrante\n",
    "\n",
    "| Nombre | e-mail |\n",
    "|------|------|\n",
    "|Rivadero, Isabel | isarivadero@hotmail.com |\n",
    "\n",
    "## Práctico de Aprendizaje supervisado y no supervisado\n",
    "Continuo trabajando sobre aprendizaje automático: sobre modelos supervisados y no supervisados. Diseño e implemento algunos modelos y defino métricas para ver como performan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Aumentar el ancho del notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "holidays = './holidays.csv'\n",
    "cols = ['service',\n",
    "        'sender_zipcode',\n",
    "        'receiver_zipcode',\n",
    "        'sender_state',\n",
    "        'receiver_state',\n",
    "        'shipment_type',\n",
    "        'quantity',\n",
    "        'status',\n",
    "        'date_created',\n",
    "        'date_sent',\n",
    "        'date_visit',\n",
    "        'target']\n",
    "data_path = './shipments_BR_201903.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ontimesv(y_test, y_pred):\n",
    "    ontime_sv= (y_pred == y_test)\n",
    "    return np.sum(ontime_sv) / np.size(y_test)\n",
    "\n",
    "def delaysv(y_test, y_pred):\n",
    "    delay_sv = (y_pred < y_test)\n",
    "    return np.sum(delay_sv) / np.size(y_test)\n",
    "\n",
    "def earlysv(y_test, y_pred):\n",
    "    early_sv= (y_test < y_pred)\n",
    "    return np.sum(early_sv) / np.size(y_test)\n",
    "\n",
    "def offset_window(y_test, lower_bound, upper_bound, length):\n",
    "    offset_msk = ((upper_bound - lower_bound) == length)\n",
    "    return np.sum(offset_msk) / np.size(offset_msk)\n",
    "\n",
    "\n",
    "def avg_speed(y_test, lower_bound, upper_bound):\n",
    "    return lower_bound.mean()\n",
    "\n",
    "\n",
    "def avg_offset(y_test, lower_bound, upper_bound):\n",
    "    return (upper_bound - lower_bound).mean()\n",
    "\n",
    "def get_metrics(y_test, speed, offset):\n",
    "    lower_bound = speed\n",
    "    upper_bound = speed + offset\n",
    "    metrics = {'on_time': ontime(y_test, lower_bound, upper_bound).astype(float).round(3),\n",
    "               'delay': delay(y_test, lower_bound, upper_bound).astype(float).round(3),\n",
    "               'early': early(y_test, lower_bound, upper_bound).astype(float).round(3),\n",
    "               'offset_0': offset_window(y_test, lower_bound, upper_bound, 0).astype(float).round(3),\n",
    "               'offset_1': offset_window(y_test, lower_bound, upper_bound, 1).astype(float).round(3),\n",
    "               'offset_2': offset_window(y_test, lower_bound, upper_bound, 2).astype(float).round(3),\n",
    "               'avg_speed': avg_speed(y_test, lower_bound, upper_bound).astype(float).round(3),\n",
    "               'avg_offset': avg_offset(y_test, lower_bound, upper_bound).astype(float).round(3),\n",
    "               }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Referencia de las columnas\n",
    "* **service**: Identificador unico que corresponde a un tipo de servicio de un correo en particular.\n",
    "* **sender_zipcode:** Código postal de quien envía el paquete (usualmente el vendedor).\n",
    "* **receiver_zipcode:** Código postal de quien recibe el paquete (usualmente el comprador).\n",
    "* **sender_state:** Nombre abreviado del estado de quien envía el paquete.\n",
    "* **receiver_state:** Nombre abreviado del estado de quien recibe el paquete.\n",
    "* **quantity:** Cantidad de items que tiene dentro el paquete.\n",
    "* **status:** Estado final del envío.\n",
    "* **date_created:** Fecha de compra de el o los items.\n",
    "* **date_sent:** Fecha en que el correo recibe el paquete.\n",
    "* **date_visit:** Fecha en que el correo entrega el paquete.\n",
    "* **target:** Cantidad de dias hábiles que tardó el correo en entregar el paquete desde que lo recibe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path, usecols=cols)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender_state</th>\n",
       "      <th>sender_zipcode</th>\n",
       "      <th>receiver_state</th>\n",
       "      <th>receiver_zipcode</th>\n",
       "      <th>shipment_type</th>\n",
       "      <th>quantity</th>\n",
       "      <th>service</th>\n",
       "      <th>status</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_sent</th>\n",
       "      <th>date_visit</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP</td>\n",
       "      <td>3005</td>\n",
       "      <td>SP</td>\n",
       "      <td>5409</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-04 00:00:00</td>\n",
       "      <td>2019-03-05 13:24:00</td>\n",
       "      <td>2019-03-07 18:01:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP</td>\n",
       "      <td>17052</td>\n",
       "      <td>MG</td>\n",
       "      <td>37750</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-19 00:00:00</td>\n",
       "      <td>2019-03-20 14:44:00</td>\n",
       "      <td>2019-03-27 10:21:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP</td>\n",
       "      <td>2033</td>\n",
       "      <td>SP</td>\n",
       "      <td>11040</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-02-18 00:00:00</td>\n",
       "      <td>2019-02-21 15:08:00</td>\n",
       "      <td>2019-02-28 18:19:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP</td>\n",
       "      <td>13900</td>\n",
       "      <td>SP</td>\n",
       "      <td>18500</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-09 00:00:00</td>\n",
       "      <td>2019-03-11 15:48:00</td>\n",
       "      <td>2019-03-12 13:33:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP</td>\n",
       "      <td>4361</td>\n",
       "      <td>RS</td>\n",
       "      <td>96810</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-08 00:00:00</td>\n",
       "      <td>2019-03-12 08:19:00</td>\n",
       "      <td>2019-03-16 08:24:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sender_state  sender_zipcode receiver_state  receiver_zipcode shipment_type  \\\n",
       "0           SP            3005             SP              5409       express   \n",
       "1           SP           17052             MG             37750      standard   \n",
       "2           SP            2033             SP             11040       express   \n",
       "3           SP           13900             SP             18500       express   \n",
       "4           SP            4361             RS             96810       express   \n",
       "\n",
       "   quantity  service status         date_created            date_sent  \\\n",
       "0         1        0   done  2019-03-04 00:00:00  2019-03-05 13:24:00   \n",
       "1         1        1   done  2019-03-19 00:00:00  2019-03-20 14:44:00   \n",
       "2         1        0   done  2019-02-18 00:00:00  2019-02-21 15:08:00   \n",
       "3         1        0   done  2019-03-09 00:00:00  2019-03-11 15:48:00   \n",
       "4         1        0   done  2019-03-08 00:00:00  2019-03-12 08:19:00   \n",
       "\n",
       "            date_visit  target  \n",
       "0  2019-03-07 18:01:00       2  \n",
       "1  2019-03-27 10:21:00       5  \n",
       "2  2019-02-28 18:19:00       5  \n",
       "3  2019-03-12 13:33:00       1  \n",
       "4  2019-03-16 08:24:00       4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sender_state        object\n",
       "sender_zipcode       int64\n",
       "receiver_state      object\n",
       "receiver_zipcode     int64\n",
       "shipment_type       object\n",
       "quantity             int64\n",
       "service              int64\n",
       "status              object\n",
       "date_created        object\n",
       "date_sent           object\n",
       "date_visit          object\n",
       "target               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como las fechas estan como tipo objeto no voy a poder operar entonces paso a tipo fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['date_created']= df1.date_created.astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['date_sent']= df1.date_sent.astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['date_visit']= df1.date_visit.astype('datetime64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eliminamos datos inconsistentes:**\n",
    "\n",
    "Aplicamos curacion y limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df1[(df1['date_sent'] <= df1['date_visit']) & (df1['date_created'] <= df1['date_sent']) & (df1['date_created'] <= df1['date_visit'])]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los features\n",
    "#### Diseñar un pipeline con las siguientes transformaciones:\n",
    "1- Recortar el último dígito de los zip codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['sender_zipcode']=df1['sender_zipcode']/10\n",
    "df1['sender_zipcode'] =df1['sender_zipcode'].astype('int32')\n",
    "df1['receiver_zipcode']=df1['receiver_zipcode']/10\n",
    "df1['receiver_zipcode'] =df1['receiver_zipcode'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sender_state                object\n",
       "sender_zipcode               int32\n",
       "receiver_state              object\n",
       "receiver_zipcode             int32\n",
       "shipment_type               object\n",
       "quantity                     int64\n",
       "service                      int64\n",
       "status                      object\n",
       "date_created        datetime64[ns]\n",
       "date_sent           datetime64[ns]\n",
       "date_visit          datetime64[ns]\n",
       "target                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender_state</th>\n",
       "      <th>sender_zipcode</th>\n",
       "      <th>receiver_state</th>\n",
       "      <th>receiver_zipcode</th>\n",
       "      <th>shipment_type</th>\n",
       "      <th>quantity</th>\n",
       "      <th>service</th>\n",
       "      <th>status</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_sent</th>\n",
       "      <th>date_visit</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP</td>\n",
       "      <td>300</td>\n",
       "      <td>SP</td>\n",
       "      <td>540</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>2019-03-05 13:24:00</td>\n",
       "      <td>2019-03-07 18:01:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP</td>\n",
       "      <td>1705</td>\n",
       "      <td>MG</td>\n",
       "      <td>3775</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-19</td>\n",
       "      <td>2019-03-20 14:44:00</td>\n",
       "      <td>2019-03-27 10:21:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP</td>\n",
       "      <td>203</td>\n",
       "      <td>SP</td>\n",
       "      <td>1104</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-02-18</td>\n",
       "      <td>2019-02-21 15:08:00</td>\n",
       "      <td>2019-02-28 18:19:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP</td>\n",
       "      <td>1390</td>\n",
       "      <td>SP</td>\n",
       "      <td>1850</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-09</td>\n",
       "      <td>2019-03-11 15:48:00</td>\n",
       "      <td>2019-03-12 13:33:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP</td>\n",
       "      <td>436</td>\n",
       "      <td>RS</td>\n",
       "      <td>9681</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>2019-03-12 08:19:00</td>\n",
       "      <td>2019-03-16 08:24:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sender_state  sender_zipcode receiver_state  receiver_zipcode shipment_type  \\\n",
       "0           SP             300             SP               540       express   \n",
       "1           SP            1705             MG              3775      standard   \n",
       "2           SP             203             SP              1104       express   \n",
       "3           SP            1390             SP              1850       express   \n",
       "4           SP             436             RS              9681       express   \n",
       "\n",
       "   quantity  service status date_created           date_sent  \\\n",
       "0         1        0   done   2019-03-04 2019-03-05 13:24:00   \n",
       "1         1        1   done   2019-03-19 2019-03-20 14:44:00   \n",
       "2         1        0   done   2019-02-18 2019-02-21 15:08:00   \n",
       "3         1        0   done   2019-03-09 2019-03-11 15:48:00   \n",
       "4         1        0   done   2019-03-08 2019-03-12 08:19:00   \n",
       "\n",
       "           date_visit  target  \n",
       "0 2019-03-07 18:01:00       2  \n",
       "1 2019-03-27 10:21:00       5  \n",
       "2 2019-02-28 18:19:00       5  \n",
       "3 2019-03-12 13:33:00       1  \n",
       "4 2019-03-16 08:24:00       4  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Normalizar los features para que queden en el rango (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['sender_zipcode', 'receiver_zipcode', 'service']\n",
    "target = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((673645, 3), (673645,), (76378, 3), (76378,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_off = '2019-03-20'\n",
    "df_train = df.query(f'date_visit <= \"{cut_off}\"')\n",
    "df_test = df.query(f'date_created > \"{cut_off}\"')\n",
    "\n",
    "X_train = df_train[features].values.astype(np.float)\n",
    "y_train = df_train[target].values\n",
    "\n",
    "X_test = df_test[features].values.astype(np.float)\n",
    "y_test = df_test[target].values\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preguntar porque lo transforma a numpy con np.float o values, que cambia si no ponemos eso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_n=scaler.transform(X_train)\n",
    "scaler.fit(X_test)\n",
    "X_test_n=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02024876, 0.0445302 , 0.        ],\n",
       "       [0.01042751, 0.10141531, 0.        ],\n",
       "       [0.13033374, 0.17677722, 0.        ],\n",
       "       ...,\n",
       "       [0.06156473, 0.60431967, 0.09090909],\n",
       "       [0.03493013, 0.37791068, 0.09090909],\n",
       "       [0.1650921 , 0.02473002, 0.09090909]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88959969, 0.86685054, 0.1       ],\n",
       "       [0.35835632, 0.88254074, 0.1       ],\n",
       "       [0.06140537, 0.19184878, 0.        ],\n",
       "       ...,\n",
       "       [0.07639289, 0.11360996, 0.        ],\n",
       "       [0.12331605, 0.06131604, 0.        ],\n",
       "       [0.3880686 , 0.03471443, 0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Proyectar los features utilizando PCA, manteniendo 3 componentes.\n",
    "#### NOTA IMPORTANTE: \n",
    "Estas transformaciones se deben aplicar sin modificar el dataframe con los datos originales, pueden usar copias para hacer las pruebas. Es decir que no deben hacer las transformaciones y guardarlas en un dataframe, tal como se hace en el ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA preguntarrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=3, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.08603379e+04, -4.85691094e+03, -1.22822702e+00],\n",
       "       [-3.59869638e+04, -7.84072901e+03, -1.24328056e+00],\n",
       "       [-2.46701287e+04,  4.30095151e+02, -1.17465126e+00],\n",
       "       ...,\n",
       "       [ 1.21421767e+04, -2.15318603e+04, -2.84429183e-01],\n",
       "       [-9.65780269e+03, -1.57002964e+04, -2.68311202e-01],\n",
       "       [-3.73849880e+04,  9.18786630e+03, -1.28745915e-01]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del target:\n",
    "4- Limitar el target a 20, es decir asignar todo target mayor que 20 a 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[df1['target']>20, 'target'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     159537\n",
       "2     135145\n",
       "3     107500\n",
       "4      82250\n",
       "5      68790\n",
       "6      59190\n",
       "7      51902\n",
       "8      47937\n",
       "9      42376\n",
       "10     40461\n",
       "11     35821\n",
       "12     30215\n",
       "13     25068\n",
       "20     21344\n",
       "0      21118\n",
       "14     19853\n",
       "15     16241\n",
       "16     12133\n",
       "17      9724\n",
       "18      7340\n",
       "19      6055\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del dataset:\n",
    "5- Particionar el dataset en train y test, teniendo los cuidados necesarios para no romper la temporalidad de los datos. El conjunto de training no puede tener menos del 50% de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ya esta hecho en 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- Si les parece necesario, pueden realizar algún tipo de filtrado o limpieza de los\n",
    "datos, explicando por qué les parece necesario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ya lo hicimos antes, pero vimos que no habia datos incosistentes porque ninguno quedo filtrado entonces no seria necesario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo basado en árboles de decisión (supervisado)\n",
    "7- Crear un pipeline con los pasos de “preparación de los features” agregando el clasificador XGBoostClassifier como estimador final. Entrenar este modelo, predecir el conjunto de test y calcular las métricas ontime, delay y early, sin ventana (se puede utilizar un array con ceros como en el ejemplo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('normalizer', MinMaxScaler()),\n",
    "    ('classifier', XGBClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 31s, sys: 1.14 s, total: 31min 32s\n",
      "Wall time: 31min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('normalizer', MinMaxScaler(copy=True, feature_range=(0, 1))), ('classifier', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,...\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 2, ..., 1, 1, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ontimesv': 0.5011652570111812,\n",
       " 'delaysv': 0.2351200607504779,\n",
       " 'earlysv': 0.2637146822383409}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {\n",
    "    'ontimesv': ontimesv(y_test, y_pred),\n",
    "    'delaysv': delaysv(y_test, y_pred),\n",
    "    'earlysv': earlysv(y_test, y_pred),\n",
    "}\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8- Explicar muy brevemente como funcionan esta clase de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leer documentacion de xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo basado en vecinos cercanos (no supervisado / semi supervisado)\n",
    "9- Crear un pipeline con los pasos de “preparación de los features” agregando el clasificador KNeighborsClassifier como estimador final. Entrenar este modelo, predecir el conjunto de test y calcular las métricas ontime, delay y early, sin ventana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('normalizer', MinMaxScaler()),\n",
    "    ('classifier',  KNeighborsClassifier(n_neighbors=3)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 8s, sys: 676 ms, total: 3min 9s\n",
      "Wall time: 3min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('normalizer', MinMaxScaler(copy=True, feature_range=(0, 1))), ('classifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 7, 1, ..., 1, 1, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ontimesv': 0.43270313441043234,\n",
       " 'delaysv': 0.2867710597292414,\n",
       " 'earlysv': 0.28052580586032627}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {\n",
    "    'ontimesv': ontimesv(y_test, y_pred),\n",
    "    'delaysv': delaysv(y_test, y_pred),\n",
    "    'earlysv': earlysv(y_test, y_pred),\n",
    "}\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10- Explicar muy brevemente como funcionan esta clase de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ver documentacion de KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo basado en regresión:\n",
    "11- Crear un pipeline con los pasos de “preparación de los features” agregando un regresor a elección de ustedes como estimador final. Este regresor puede ser tanto supervisado como no supervisado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('normalizer', MinMaxScaler()),\n",
    "    ('classifier', LogisticRegression(solver ='newton-cg',multi_class ='multinomial')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12- Entrenar este modelo, predecir el conjunto de test y redondear las predicciones de forma inteligente. Explicar el criterio de redondeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48min 23s, sys: 16min 25s, total: 1h 4min 48s\n",
      "Wall time: 54min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('normalizer', MinMaxScaler(copy=True, feature_range=(0, 1))), ('classifier', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 3, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## como que redondear?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13- Calcular las métricas ontime , delay y early, sin ventana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ontimesv': 0.4323234439236429,\n",
       " 'delaysv': 0.40668778967765584,\n",
       " 'earlysv': 0.1609887663987012}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {\n",
    "    'ontimesv': ontimesv(y_test, y_pred),\n",
    "    'delaysv': delaysv(y_test, y_pred),\n",
    "    'earlysv': earlysv(y_test, y_pred),\n",
    "}\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14- Justificar muy brevemente la elección del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ventanas de predicción:\n",
    "15- Construir un offset para mejorar las predicciones de nuestros modelos, de forma que tenga avg_offset menor o igual a 1, recalcular las métricas y explicar cómo se lo construyó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ontime(y_test, lower_bound, upper_bound):\n",
    "    ontime_msk = (lower_bound <= y_test) & (y_test <= upper_bound)\n",
    "    return np.sum(ontime_msk) / np.size(y_test)\n",
    "\n",
    "def delay(y_test, lower_bound, upper_bound):\n",
    "    delay_msk = (upper_bound < y_test)\n",
    "    return np.sum(delay_msk) / np.size(y_test)\n",
    "\n",
    "def early(y_test, lower_bound, upper_bound):\n",
    "    early_msk = (y_test < lower_bound)\n",
    "    return np.sum(early_msk) / np.size(y_test)\n",
    "\n",
    "def offset_window(y_test, lower_bound, upper_bound, length):\n",
    "    offset_msk = ((upper_bound - lower_bound) == length)\n",
    "    return np.sum(offset_msk) / np.size(offset_msk)\n",
    "\n",
    "def avg_speed(y_test, lower_bound, upper_bound):\n",
    "    return lower_bound.mean()\n",
    "\n",
    "def avg_offset(y_test, lower_bound, upper_bound):\n",
    "    return (upper_bound - lower_bound).mean()\n",
    "\n",
    "def get_metrics(y_test, speed, offset):\n",
    "    lower_bound = speed\n",
    "    upper_bound = speed + offset\n",
    "    metrics = {'on_time': ontime(y_test, lower_bound, upper_bound).astype(float).round(3),\n",
    "               'delay': delay(y_test, lower_bound, upper_bound).astype(float).round(3),\n",
    "               'early': early(y_test, lower_bound, upper_bound).astype(float).round(3),\n",
    "               'offset_0': offset_window(y_test, lower_bound, upper_bound, 0).astype(float).round(3),\n",
    "               'offset_1': offset_window(y_test, lower_bound, upper_bound, 1).astype(float).round(3),\n",
    "               'offset_2': offset_window(y_test, lower_bound, upper_bound, 2).astype(float).round(3),\n",
    "               'avg_speed': avg_speed(y_test, lower_bound, upper_bound).astype(float).round(3),\n",
    "               'avg_offset': avg_offset(y_test, lower_bound, upper_bound).astype(float).round(3),\n",
    "               }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'on_time': 0.432,\n",
       " 'delay': 0.407,\n",
       " 'early': 0.161,\n",
       " 'offset_0': 1.0,\n",
       " 'offset_1': 0.0,\n",
       " 'offset_2': 0.0,\n",
       " 'avg_speed': 1.691,\n",
       " 'avg_offset': 0.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "offset = np.zeros_like(y_pred)\n",
    "get_metrics(y_test, y_pred, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16- Construir un offset que mejore las métricas de los modelo y que además tenga un avg_offset menor o igual que 2.5, recalcular las métricas y explicar cómo se lo construyó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "offset = np.zeros_like(y_pred)\n",
    "get_metrics(y_test, y_pred, offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como generar el offset, como generar numeros aleatorios?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
